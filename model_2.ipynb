{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model packages\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Reshape, Activation, LSTM, TimeDistributed, BatchNormalization, Dropout\n",
    "\n",
    "# Dataset management packages\n",
    "from spivutils.synthetic_datasets.spid import load_data\n",
    "from spivutils.batch_generators.keras_generator import batch_data\n",
    "from spivutils.common_tools.operations import normalization, vectoraddition, thresholding\n",
    "\n",
    "# General purpose packages\n",
    "import numpy as np\n",
    "import gc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hardware Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_devices = tf.config.list_physical_devices('CPU')\n",
    "gpu_devices = tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force CPU usage\n",
    "tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 100                                        # Slice  of the dataset\n",
    "batch_size = 16                                         # Number of patterns shown to the network before weight matrix update\n",
    "epochs = 50                                             # Number of times that the model sees the dataset\n",
    "activation = 'relu', 'linear'                           #\n",
    "optimizer = 'adam'                                      # Weight update after each iteration\n",
    "\n",
    "learning_rate = 0.001                                           \n",
    "dropout = 0.5\n",
    "\n",
    "dense_units = [32, 64, 128, 256, 512, 1024, 2048]       # Hidden units per layer\n",
    "lstm_units = [32, 64, 128, 256, 512, 1024]              # Hidden units per layer\n",
    "\n",
    "filters = [32, 64, 128, 256, 512]\n",
    "kernel_size = [(3,3), (5,5), (7,7), (9,9), (11,11)]\n",
    "pool_size = [(2,2), (4,4), (6,6), (8,8), (10,10)]\n",
    "padding = 'same'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Checking files ...\n",
      "\n",
      " train_x.npy  Found!\n",
      "\n",
      " train_y.npy  Found!\n",
      "\n",
      " valid_x.npy  Found!\n",
      "\n",
      " valid_y.npy  Found!\n",
      "\n",
      " test_x.npy  Found!\n",
      "\n",
      " test_y.npy  Found!\n",
      "\n",
      " Importing data ...\n",
      "\n",
      " Data loading successful!\n"
     ]
    }
   ],
   "source": [
    "# Data importing\n",
    "(train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_data()\n",
    "\n",
    "# Collect a chunk of the dataset\n",
    "train_x_chunk = train_x#[0:chunk_size]\n",
    "train_y_chunk = train_y#[0:chunk_size]\n",
    "valid_x_chunk = valid_x#[0:chunk_size]\n",
    "valid_y_chunk = valid_y#[0:chunk_size]\n",
    "\n",
    "# Load data in batches to avoid memory overload\n",
    "train_batch = batch_data(train_x_chunk, train_y_chunk, batch_size)\n",
    "valid_batch = batch_data(valid_x_chunk, valid_y_chunk, batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add pre-processing operations\n",
    "train_batch.add_x_preprocessing_operation(thresholding)\n",
    "train_batch.add_x_preprocessing_operation(normalization)\n",
    "train_batch.add_y_preprocessing_operation(vectoraddition)\n",
    "\n",
    "valid_batch.add_x_preprocessing_operation(thresholding)\n",
    "valid_batch.add_x_preprocessing_operation(normalization)\n",
    "valid_batch.add_y_preprocessing_operation(vectoraddition)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = train_batch[0][0][0,].shape\n",
    "output_shape = train_batch[0][1][0,].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_convnet(input_shape, filters, kernel_size, pool_size, activation, padding):\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(filters = filters[0], kernel_size = kernel_size[4], padding = padding, input_shape = input_shape))\n",
    "    model.add(Activation(activation[0]))\n",
    "    model.add(MaxPooling2D(pool_size = pool_size[4]))\n",
    "\n",
    "    model.add(Conv2D(filters = filters[1], kernel_size = kernel_size[3], padding = padding))\n",
    "    model.add(Activation(activation[0]))\n",
    "    model.add(MaxPooling2D(pool_size = pool_size[3]))\n",
    "\n",
    "    model.add(Conv2D(filters = filters[2], kernel_size = kernel_size[2], padding = padding))\n",
    "    model.add(Activation(activation[0]))\n",
    "    model.add(MaxPooling2D(pool_size = pool_size[2]))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape, output_shape, filters, kernel_size, pool_size, lstm_units, dense_units, activation, padding):\n",
    "\n",
    "    convnet = build_convnet(input_shape[1:], filters, kernel_size, pool_size, activation, padding)\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(TimeDistributed(convnet, input_shape = input_shape))\n",
    "\n",
    "    model.add(LSTM(units = lstm_units[0], return_sequences = False))\n",
    "\n",
    "    model.add(Dense(units = dense_units[6]))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(units = dense_units[5]))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(units = dense_units[4]))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(units = dense_units[3]))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(units = dense_units[2]))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(units = dense_units[1]))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(units = dense_units[0]))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(np.prod(output_shape)))\n",
    "    model.add(Activation('linear'))\n",
    "\n",
    "    model.add(Reshape(output_shape))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(input_shape, output_shape, filters, kernel_size, pool_size, lstm_units, dense_units, activation, padding)\n",
    "\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed (TimeDistr  (None, 2, 128)           571392    \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 32)                20608     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2048)              67584     \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1024)              2098176   \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 256)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 64)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 32)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 418950)            13825350  \n",
      "                                                                 \n",
      " activation_10 (Activation)  (None, 418950)            0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 630, 665)          0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,282,470\n",
      "Trainable params: 17,282,470\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCall(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "945/945 [==============================] - 1085s 1s/step - loss: 5.1514 - val_loss: 4.8911\n",
      "Epoch 2/50\n",
      "945/945 [==============================] - 1020s 1s/step - loss: 4.9642 - val_loss: 5.3951\n",
      "Epoch 3/50\n",
      "945/945 [==============================] - 1022s 1s/step - loss: 4.9387 - val_loss: 5.2715\n",
      "Epoch 4/50\n",
      "945/945 [==============================] - 1011s 1s/step - loss: 4.8792 - val_loss: 5.0312\n",
      "Epoch 5/50\n",
      "945/945 [==============================] - 1005s 1s/step - loss: 4.8623 - val_loss: 4.8401\n",
      "Epoch 6/50\n",
      "945/945 [==============================] - 1025s 1s/step - loss: 4.8557 - val_loss: 4.9103\n",
      "Epoch 7/50\n",
      "945/945 [==============================] - 1017s 1s/step - loss: 4.8472 - val_loss: 4.8555\n",
      "Epoch 8/50\n",
      "945/945 [==============================] - 1004s 1s/step - loss: 4.8577 - val_loss: 4.8380\n",
      "Epoch 9/50\n",
      "945/945 [==============================] - 1012s 1s/step - loss: 4.8289 - val_loss: 4.8323\n",
      "Epoch 10/50\n",
      "945/945 [==============================] - 1056s 1s/step - loss: 4.8194 - val_loss: 4.9075\n",
      "Epoch 11/50\n",
      "945/945 [==============================] - 1008s 1s/step - loss: 4.8232 - val_loss: 4.9825\n",
      "Epoch 12/50\n",
      "537/945 [================>.............] - ETA: 6:13 - loss: 4.7890"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'gradient_tape/sequential_1/time_distributed/sequential/max_pooling2d/MaxPool/MaxPoolGrad' defined at (most recent call last):\n    File \"C:\\Users\\michel.machado\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\michel.machado\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"d:\\Pessoal\\Velocimetria\\vel_env\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"d:\\Pessoal\\Velocimetria\\vel_env\\lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"d:\\Pessoal\\Velocimetria\\vel_env\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"d:\\Pessoal\\Velocimetria\\vel_env\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\michel.machado\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"C:\\Users\\michel.machado\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"C:\\Users\\michel.machado\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"d:\\Pessoal\\Velocimetria\\vel_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"d:\\Pessoal\\Velocimetria\\vel_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"d:\\Pessoal\\Velocimetria\\vel_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"d:\\Pessoal\\Velocimetria\\vel_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"d:\\Pessoal\\Velocimetria\\vel_env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"d:\\Pessoal\\Velocimetria\\vel_env\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"d:\\Pessoal\\Velocimetria\\vel_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"d:\\Pessoal\\Velocimetria\\vel_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"d:\\Pessoal\\Velocimetria\\vel_env\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"d:\\Pessoal\\Velocimetria\\vel_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"d:\\Pessoal\\Velocimetria\\vel_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"d:\\Pessoal\\Velocimetria\\vel_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\michel.machado\\AppData\\Local\\Temp\\ipykernel_11772\\773258379.py\", line 1, in <module>\n      history = model.fit(train_batch, validation_data = valid_batch, epochs = epochs, callbacks = [CustomCall()])\n    File \"d:\\Pessoal\\Velocimetria\\vel_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\Pessoal\\Velocimetria\\vel_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"d:\\Pessoal\\Velocimetria\\vel_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"d:\\Pessoal\\Velocimetria\\vel_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"d:\\Pessoal\\Velocimetria\\vel_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"d:\\Pessoal\\Velocimetria\\vel_env\\lib\\site-packages\\keras\\engine\\training.py\", line 997, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"d:\\Pessoal\\Velocimetria\\vel_env\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 576, in minimize\n      grads_and_vars = self._compute_gradients(\n    File \"d:\\Pessoal\\Velocimetria\\vel_env\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 634, in _compute_gradients\n      grads_and_vars = self._get_gradients(\n    File \"d:\\Pessoal\\Velocimetria\\vel_env\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 510, in _get_gradients\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'gradient_tape/sequential_1/time_distributed/sequential/max_pooling2d/MaxPool/MaxPoolGrad'\nOOM when allocating tensor with shape[32,32,630,665] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node gradient_tape/sequential_1/time_distributed/sequential/max_pooling2d/MaxPool/MaxPoolGrad}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_4078]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train_batch, validation_data \u001b[39m=\u001b[39;49m valid_batch, epochs \u001b[39m=\u001b[39;49m epochs, callbacks \u001b[39m=\u001b[39;49m [CustomCall()])\n",
      "File \u001b[1;32md:\\Pessoal\\Velocimetria\\vel_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\Pessoal\\Velocimetria\\vel_env\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'gradient_tape/sequential_1/time_distributed/sequential/max_pooling2d/MaxPool/MaxPoolGrad' defined at (most recent call last):\n    File \"C:\\Users\\michel.machado\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\michel.machado\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"d:\\Pessoal\\Velocimetria\\vel_env\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"d:\\Pessoal\\Velocimetria\\vel_env\\lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"d:\\Pessoal\\Velocimetria\\vel_env\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"d:\\Pessoal\\Velocimetria\\vel_env\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\michel.machado\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"C:\\Users\\michel.machado\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"C:\\Users\\michel.machado\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"d:\\Pessoal\\Velocimetria\\vel_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"d:\\Pessoal\\Velocimetria\\vel_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"d:\\Pessoal\\Velocimetria\\vel_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"d:\\Pessoal\\Velocimetria\\vel_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"d:\\Pessoal\\Velocimetria\\vel_env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"d:\\Pessoal\\Velocimetria\\vel_env\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"d:\\Pessoal\\Velocimetria\\vel_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"d:\\Pessoal\\Velocimetria\\vel_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"d:\\Pessoal\\Velocimetria\\vel_env\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"d:\\Pessoal\\Velocimetria\\vel_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"d:\\Pessoal\\Velocimetria\\vel_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"d:\\Pessoal\\Velocimetria\\vel_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\michel.machado\\AppData\\Local\\Temp\\ipykernel_11772\\773258379.py\", line 1, in <module>\n      history = model.fit(train_batch, validation_data = valid_batch, epochs = epochs, callbacks = [CustomCall()])\n    File \"d:\\Pessoal\\Velocimetria\\vel_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\Pessoal\\Velocimetria\\vel_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"d:\\Pessoal\\Velocimetria\\vel_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"d:\\Pessoal\\Velocimetria\\vel_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"d:\\Pessoal\\Velocimetria\\vel_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"d:\\Pessoal\\Velocimetria\\vel_env\\lib\\site-packages\\keras\\engine\\training.py\", line 997, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"d:\\Pessoal\\Velocimetria\\vel_env\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 576, in minimize\n      grads_and_vars = self._compute_gradients(\n    File \"d:\\Pessoal\\Velocimetria\\vel_env\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 634, in _compute_gradients\n      grads_and_vars = self._get_gradients(\n    File \"d:\\Pessoal\\Velocimetria\\vel_env\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 510, in _get_gradients\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'gradient_tape/sequential_1/time_distributed/sequential/max_pooling2d/MaxPool/MaxPoolGrad'\nOOM when allocating tensor with shape[32,32,630,665] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node gradient_tape/sequential_1/time_distributed/sequential/max_pooling2d/MaxPool/MaxPoolGrad}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_4078]"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_batch, validation_data = valid_batch, epochs = epochs, callbacks = [CustomCall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "    loss = history.history['loss']\n",
    "    epochs = range(len(loss))\n",
    "    plt.plot(epochs, loss, 'r')\n",
    "    plt.title('Training loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plot_loss(history)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vel_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
